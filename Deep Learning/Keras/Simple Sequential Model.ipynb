{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training\n",
    "* Model methods and attributes\n",
    "* Save and Load Model\n",
    "* Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels =  []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example data: \n",
    "- An experiemental drug was tested on individuals from ages 13 to 100. \n",
    "- The trial had 2100 participants. Half were under 65 years old, half were over 65 years old.\n",
    "- 95% of patientes 65 or older experienced side effects.\n",
    "- 95% of patients under 65 experienced no side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the data in Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"Age\": train_samples, \"Side Effect?\": train_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Side Effect?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Side Effect?\n",
       "0   18             1\n",
       "1   98             0\n",
       "2   42             1\n",
       "3   83             0\n",
       "4   15             1\n",
       "5   95             0\n",
       "6   28             1\n",
       "7   74             0\n",
       "8   41             1\n",
       "9   80             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10) # Top 10 datapoints, 1 means Yes, 0 means No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Side Effect?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.102381</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.833684</td>\n",
       "      <td>0.500119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  Side Effect?\n",
       "count  2100.000000   2100.000000\n",
       "mean     60.102381      0.500000\n",
       "std      25.833684      0.500119\n",
       "min      13.000000      0.000000\n",
       "25%      37.000000      0.000000\n",
       "50%      64.500000      0.500000\n",
       "75%      82.000000      1.000000\n",
       "max     100.000000      1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalling Input in range 0 to 1 (Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to fit and transform the current Age column, it will give us a `DataConversionWarning` warning. This is because the type of `df['Age']` is `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Age'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's comvert it to float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Age'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = scaler.fit_transform((df['Age']).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Side Effect?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.804598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.942529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.172414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.701149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.321839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.770115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Side Effect?\n",
       "0  0.057471             1\n",
       "1  0.977011             0\n",
       "2  0.333333             1\n",
       "3  0.804598             0\n",
       "4  0.022989             1\n",
       "5  0.942529             0\n",
       "6  0.172414             1\n",
       "7  0.701149             0\n",
       "8  0.321839             1\n",
       "9  0.770115             0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sequential Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is a linear stack of layers.\n",
    "\n",
    "We can pass in an array each of which element will represents one layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of passing the layer in constructor we can also use add() method.\n",
    "\n",
    "```\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape(1, ), activation = 'relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "Here **Dense()** represents the first hidden layer in NN.\n",
    "\n",
    "Example from [here](http://keras.dhpit.com/):\n",
    "```\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "```\n",
    "\n",
    "It means 8 input parameters, with 12 neurons in the FIRST hidden layer.\n",
    "\n",
    "![](http://keras.dhpit.com/img/nn.png)\n",
    "\n",
    "So for our case we have 1 input parameter and in 1's hidden layer we have 16 neurons, for 2nd hidden layer we have 32 neurons and for output layer we have 2 neurons.\n",
    "\n",
    "***\n",
    "\n",
    "NOTE: *The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape.*\n",
    "\n",
    "***\n",
    "\n",
    "Other then this we have pass the activation function which needed to be applied to convert each input signal into output signals (Activation functions are applied to the weighted sum and based on the value we get after applying activation fucntion we deside whrther to pass on the signal to next neuron or not).\n",
    "\n",
    "There are quite a few activation function we should look for:\n",
    "\n",
    "**Treshold**:\n",
    "\n",
    "![](threshold.png)\n",
    "\n",
    "**Sigmoid**:\n",
    "\n",
    "![](sigmoid.png)\n",
    "\n",
    "**Rectifier**:\n",
    "\n",
    "![](rectifier.png)\n",
    "\n",
    "**Hyperbolic Tangent**:\n",
    "\n",
    "![](hyperbolicTangent.png)\n",
    "\n",
    "There are many more.\n",
    "\n",
    "***\n",
    "\n",
    "This is a simple structure of neural network\n",
    "\n",
    "![](structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the summary of the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using Adam optimization function. Optimization function are the way by which we update the weight and bias in our neural network (It does it by minimizing (or maximizing) the **Objective function** or sometime called **Error Function**. There are different optimazation fuction which may affect the way you produce the output (it may be slightly better or faster).\n",
    "\n",
    "[There are many optimization function to use from](https://keras.io/optimizers/):\n",
    "\n",
    "* Gradient Descent\n",
    "* Adagrad\n",
    "* AdaDelta\n",
    "* Adam\n",
    "\n",
    "and many more.\n",
    "\n",
    "***\n",
    "\n",
    "Loss function is used to measure the inconsistency between predicted value (y') and actual label (y).\n",
    "\n",
    "[There are many loss fucntion to use from](https://keras.io/losses/):\n",
    "\n",
    "* Mean Squared Error\n",
    "* Mean Absolute Error\n",
    "* Mean Squared Logarithmic Error\n",
    "* Categorical Cross Entropy\n",
    "\n",
    "and many more\n",
    "\n",
    "***\n",
    "\n",
    "A **[metric](https://keras.io/metrics/)** is a function that is used to judge the performance of your model. Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
    "\n",
    "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model.\n",
    "\n",
    "***\n",
    "\n",
    "All we are doing here is compiling the model. This is only neccesary when we are *training* the model, but not when we are *predicting* something using a pretrained model.\n",
    "\n",
    "This is because when training the model we need to do both *forward pass* and *back pass*. So we need to specify which optimization function we need to use to update the weight and biases or what loss function we need to use. But when predicting we just need one forward pass. Hence no compiling is required while predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 0.6581 - acc: 0.5562\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6237 - acc: 0.7110\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.5881 - acc: 0.7652\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5547 - acc: 0.7995\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5206 - acc: 0.8295\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.4867 - acc: 0.8548\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4543 - acc: 0.8662\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.4248 - acc: 0.8810\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3987 - acc: 0.8871\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.3763 - acc: 0.9024\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.3575 - acc: 0.9067\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.3418 - acc: 0.9119\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.3288 - acc: 0.9143\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.3185 - acc: 0.9200\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.3097 - acc: 0.9214\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3025 - acc: 0.9233\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2967 - acc: 0.9248\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2920 - acc: 0.9276\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2879 - acc: 0.9295\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2844 - acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d42ce86d8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = df['Age'], y = df['Side Effect?'], batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pass the independent and dependent parameter (x and y) folowed by batch size.\n",
    "\n",
    "Batch size is **number of samples** passed through a network at one time. \n",
    "\n",
    "Why not pass one by one?\n",
    "\n",
    "It's better to pass more than one sample at a time if our machine can easily haddle them. It make the process of training the model fast. But there is a trade off.\n",
    "\n",
    "Larger batch sizes => faster progress in training but don't always converge as fast. \n",
    "\n",
    "Smaller batch sizes => train slower, but can converge faster.\n",
    "\n",
    "So it depends on the type of problem and is one of the very important hyperparameter.\n",
    "\n",
    "***\n",
    "\n",
    "Epoch is one pass over the entire dataset.\n",
    "\n",
    "***\n",
    "\n",
    "Think, we have **dataset of 1000 samples** and we are training out model using **batch size of 10 samples**. Now 1 epoch will be completed when we have passed 100 batch.\n",
    "\n",
    "i.e. `1000 samples / 10 samples per batch = 100 batch per epoch`\n",
    "\n",
    "***\n",
    "\n",
    "`Shuffle = True` tell that we should shuffle the data and in each epoch the data (samples) are going to be in different order.\n",
    "\n",
    "***\n",
    "\n",
    "verbose is just specifying how we should see the output.\n",
    "\n",
    "0 = silent, 1 = progress bar, 2 = one line per epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.7188 - acc: 0.4571 - val_loss: 0.7057 - val_acc: 0.3857\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6913 - acc: 0.4582 - val_loss: 0.6767 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6667 - acc: 0.5995 - val_loss: 0.6493 - val_acc: 0.6429\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6423 - acc: 0.6646 - val_loss: 0.6217 - val_acc: 0.6810\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.6169 - acc: 0.7048 - val_loss: 0.5921 - val_acc: 0.7286\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5902 - acc: 0.7354 - val_loss: 0.5608 - val_acc: 0.7714\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.5621 - acc: 0.7656 - val_loss: 0.5294 - val_acc: 0.8000\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.5362 - acc: 0.7942 - val_loss: 0.4993 - val_acc: 0.8095\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.5104 - acc: 0.8175 - val_loss: 0.4691 - val_acc: 0.8381\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.4854 - acc: 0.8344 - val_loss: 0.4397 - val_acc: 0.8571\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.4612 - acc: 0.8503 - val_loss: 0.4116 - val_acc: 0.8810\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.4387 - acc: 0.8640 - val_loss: 0.3848 - val_acc: 0.9000\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.4180 - acc: 0.8709 - val_loss: 0.3601 - val_acc: 0.9000\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.3993 - acc: 0.8815 - val_loss: 0.3373 - val_acc: 0.9143\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.3826 - acc: 0.8915 - val_loss: 0.3165 - val_acc: 0.9333\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3680 - acc: 0.8910 - val_loss: 0.2979 - val_acc: 0.9381\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3550 - acc: 0.9032 - val_loss: 0.2810 - val_acc: 0.9524\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3438 - acc: 0.9079 - val_loss: 0.2660 - val_acc: 0.9524\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3343 - acc: 0.9079 - val_loss: 0.2526 - val_acc: 0.9524\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3259 - acc: 0.9132 - val_loss: 0.2408 - val_acc: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d3f0f3b70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreating the archietecture and configuration\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer = Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training with validation\n",
    "model.fit(x = df['Age'], y = df['Side Effect?'], validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Set** is basically used to minimize overfitting. It is used during training phase but the thing is that you are nottraining over this data. You are just verifying that the increase in accuracy in taining data actually yeilds an increase in accuracy for a data which was never show to the network before.\n",
    "\n",
    "Above you can see we have two extra parameters in the output `val_loss` (Loss over validation data) and `val_acc` (Accuracy over validation data).\n",
    "\n",
    "NOTE: *If the accuracy on the training set is increasing but the accuracy in the validation set is same or decreasing then we should probably stop training as because we are just overfiting over the training data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model methods and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **model.layers** is a flattened list of the layers comprising the model.\n",
    "\n",
    "\n",
    "* **model.inputs** is the list of input tensors of the model.\n",
    "\n",
    "\n",
    "* **model.outputs** is the list of output tensors of the model.\n",
    "\n",
    "\n",
    "* **model.summary()** prints a summary representation of your model.\n",
    "\n",
    "\n",
    "* **model.get_config()** returns a dictionary containing the configuration of the model. The model can be reinstantiated from its config.\n",
    "\n",
    "\n",
    "* **model.get_weights()** returns a list of all weight tensors in the model, as Numpy arrays.\n",
    "\n",
    "\n",
    "* **model.set_weights(weights)** sets the values of the weights of the model, from a list of Numpy arrays. The arrays in the list should have the same shape as those returned by get_weights().\n",
    "\n",
    "\n",
    "* **model.to_json()** returns a representation of the model as a JSON string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the JSON string.\n",
    "\n",
    "    \n",
    "* **model.to_yaml()** returns a representation of the model as a YAML string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the YAML string.\n",
    "\n",
    "\n",
    "* **model.save_weights(filepath)** saves the weights of the model as a HDF5 file.\n",
    "\n",
    "\n",
    "* **model.load_weights(filepath, by_name=False)** loads the weights of the model from a HDF5 file (created by  save_weights). By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use by_name=True to load only those layers with the same name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/loading whole models (architecture + weights + optimizer state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use model.save(filepath) to save a Keras model into a single HDF5 file which will contain:\n",
    "\n",
    "* the architecture of the model, allowing to re-create the model\n",
    "* the weights of the model\n",
    "* the training configuration (loss, optimizer)\n",
    "* the state of the optimizer, allowing to resume training exactly where you left off.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing model\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight of each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to see the weights:\n",
    "\n",
    "** Print weight for each layer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7f6d3edfd588>,\n",
       " <keras.layers.core.Dense at 0x7f6d3eedc3c8>,\n",
       " <keras.layers.core.Dense at 0x7f6d3eda8438>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "\n",
      "Layer 1 weight: \n",
      "\n",
      " [array([[-0.11916009, -0.30759248, -0.04751443, -0.48624253, -0.42579335,\n",
      "         0.31345192,  0.34904912,  0.23672101,  0.75624794, -0.12187678,\n",
      "         0.4269982 ,  0.29224756,  0.1892598 ,  0.68758857,  0.72258794,\n",
      "        -0.26506439]], dtype=float32), array([ 0.        ,  0.        ,  0.24352528,  0.        ,  0.        ,\n",
      "        0.11395515,  0.18912597, -0.06024418, -0.1510088 ,  0.        ,\n",
      "       -0.1254327 , -0.06175768, -0.06024124, -0.13476065, -0.14081366,  0.        ], dtype=float32)]\n",
      "======================================================================================================\n",
      "\n",
      "Layer 2 weight: \n",
      "\n",
      " [array([[ 0.3069357 , -0.31109902,  0.05524549, -0.05416191, -0.1555647 ,\n",
      "         0.289103  ,  0.24298915, -0.29186827,  0.13510418,  0.1015529 ,\n",
      "        -0.02454144,  0.19875541,  0.14534298, -0.01244098, -0.10384941,\n",
      "         0.26365915, -0.06930619,  0.01960906,  0.24268928,  0.03361362,\n",
      "        -0.20039587, -0.22970293, -0.15259595,  0.31663182, -0.14352974,\n",
      "         0.27723423, -0.02870452, -0.24521963, -0.22228931,  0.23598525,\n",
      "        -0.15924749, -0.16258164],\n",
      "       [ 0.08632585, -0.30093515,  0.19478568,  0.34029594,  0.2275041 ,\n",
      "         0.22241178, -0.0343577 ,  0.08427414,  0.04572409,  0.05916423,\n",
      "         0.27613571, -0.06830874, -0.35176897,  0.06049564, -0.32074779,\n",
      "        -0.18216147,  0.24332878, -0.30870998,  0.22710368,  0.13576099,\n",
      "         0.32227901, -0.28103459,  0.27397129, -0.13553314, -0.24053273,\n",
      "         0.28664771,  0.16515991,  0.18535587,  0.05550411, -0.07019407,\n",
      "        -0.20539574,  0.20283195],\n",
      "       [-0.36924258, -0.30365658, -0.08808804, -0.34326854,  0.40230805,\n",
      "        -0.15413591,  0.05416599, -0.05220227,  0.06076613, -0.33502337,\n",
      "        -0.23688132,  0.09778441, -0.13928816, -0.30628562, -0.3254956 ,\n",
      "         0.43890026, -0.02866068,  0.35067967, -0.16505145,  0.00231954,\n",
      "        -0.30512244, -0.20576167,  0.21963552, -0.10038799, -0.07094997,\n",
      "        -0.1111248 ,  0.20207709,  0.52253139, -0.04829076,  0.20049232,\n",
      "        -0.22261173, -0.17694092],\n",
      "       [-0.26780131,  0.15646335, -0.08285001,  0.10862464, -0.33990657,\n",
      "        -0.18508384,  0.32404324, -0.01472056,  0.30441192,  0.26286045,\n",
      "        -0.02943662, -0.1773992 , -0.08054802, -0.03031757, -0.20453157,\n",
      "        -0.0173215 , -0.0439772 , -0.03734735,  0.06484294, -0.10689773,\n",
      "         0.07012519, -0.00758627, -0.23912561,  0.2489697 , -0.33535042,\n",
      "         0.23785743,  0.33387652,  0.08109316,  0.21725932,  0.04258373,\n",
      "         0.25407079,  0.14623708],\n",
      "       [ 0.00535342, -0.24750619,  0.12400302,  0.23234287, -0.05179805,\n",
      "         0.27566674, -0.07514057,  0.31823137, -0.08534038,  0.08020544,\n",
      "         0.12110248,  0.03589925,  0.34708461, -0.30863285, -0.23474547,\n",
      "        -0.04042193,  0.15496662,  0.0279099 ,  0.10684916,  0.34991172,\n",
      "         0.165176  ,  0.27750698, -0.31157672,  0.23462865,  0.29241475,\n",
      "         0.15076002, -0.00435957,  0.27937779, -0.33436579,  0.16600171,\n",
      "        -0.29466647,  0.31912836],\n",
      "       [-0.13160168, -0.23370495, -0.09790808, -0.18727766, -0.05146392,\n",
      "         0.25641996,  0.14972709, -0.06329995, -0.162635  , -0.07537787,\n",
      "         0.22205451, -0.08330593,  0.18038787, -0.18755558, -0.19531408,\n",
      "         0.2008501 ,  0.06353403,  0.06461938, -0.34208861,  0.42440885,\n",
      "         0.27876475, -0.10479738, -0.09521961,  0.21352957,  0.34211275,\n",
      "        -0.34111661,  0.1070687 ,  0.02749379,  0.04420412,  0.02738637,\n",
      "         0.31642792, -0.00267602],\n",
      "       [ 0.32192972, -0.27060956,  0.24569337, -0.22758809,  0.33776975,\n",
      "         0.10350902,  0.10619102, -0.29542324, -0.21133003,  0.28061688,\n",
      "         0.33129418, -0.23427604, -0.01935884,  0.00662616,  0.23077643,\n",
      "         0.22490561,  0.15082563, -0.14646178, -0.16953014,  0.13489789,\n",
      "        -0.14456823, -0.00316867, -0.06509987, -0.14504316,  0.39798024,\n",
      "         0.12055415, -0.04373154,  0.17976421, -0.04551184, -0.1123528 ,\n",
      "         0.38332674,  0.03633727],\n",
      "       [-0.03679751,  0.08841625, -0.03604515, -0.14171278, -0.19518118,\n",
      "         0.45724726, -0.10941526,  0.20900418,  0.20193139, -0.25457034,\n",
      "         0.55632299,  0.19019631, -0.01943509,  0.27025905,  0.01793735,\n",
      "         0.03409919, -0.00902436,  0.04133455,  0.33416912, -0.36688018,\n",
      "        -0.17686571,  0.09180671,  0.54240841,  0.20153655,  0.15983216,\n",
      "        -0.2235586 , -0.36391708,  0.1913828 , -0.22369532,  0.04585705,\n",
      "        -0.00476603,  0.18726967],\n",
      "       [-0.34722167,  0.31560293, -0.03883233,  0.22030547, -0.26013932,\n",
      "         0.4345606 , -0.14380766,  0.15668453,  0.05878222,  0.19397919,\n",
      "         0.35191417, -0.24075806,  0.0014064 , -0.24039972,  0.18167803,\n",
      "        -0.11913206,  0.26946557,  0.02627526, -0.23976314, -0.15507333,\n",
      "        -0.17379135, -0.24323866,  0.2255687 ,  0.41110215,  0.52564669,\n",
      "         0.19653144,  0.09724794, -0.2724874 , -0.15019366, -0.18542592,\n",
      "         0.25020334,  0.12325708],\n",
      "       [ 0.02456722,  0.21599409, -0.23195399,  0.32190159,  0.03943881,\n",
      "         0.24427608, -0.34408635,  0.26794109,  0.21411064, -0.20584504,\n",
      "         0.03960311, -0.30614796, -0.11312366, -0.11828943, -0.01322493,\n",
      "         0.23759833, -0.0576773 ,  0.04688543, -0.06288007, -0.1826335 ,\n",
      "         0.05099905, -0.31138134, -0.3184233 ,  0.12659624,  0.34493193,\n",
      "         0.14475882, -0.06736979,  0.31427351,  0.20016274,  0.16370282,\n",
      "        -0.28877047,  0.24249014],\n",
      "       [ 0.31072903, -0.06173703,  0.0333631 , -0.2481544 , -0.47613421,\n",
      "         0.17150049, -0.45164746, -0.11809359,  0.07879961,  0.27630419,\n",
      "         0.41751939, -0.29567102,  0.10333388, -0.0898329 ,  0.03492281,\n",
      "        -0.39618304, -0.32418159, -0.42702356,  0.03505799, -0.52159297,\n",
      "        -0.25507557, -0.00474378,  0.11839829,  0.30655816,  0.2284009 ,\n",
      "         0.0414162 , -0.34650153, -0.29481688, -0.21435575, -0.30369848,\n",
      "         0.0628026 , -0.08813549],\n",
      "       [-0.2834723 ,  0.32956317,  0.15808199, -0.10226268, -0.21273507,\n",
      "         0.25017777,  0.00296953, -0.32133701, -0.14811894,  0.09919962,\n",
      "         0.01800367, -0.05451611, -0.34759697,  0.05378106, -0.32738528,\n",
      "         0.00542432,  0.27419007,  0.20093316,  0.13437435, -0.20991971,\n",
      "        -0.11866917, -0.15441079,  0.13374051,  0.5045405 ,  0.10101692,\n",
      "         0.07254559, -0.06487841, -0.19663534, -0.27566659, -0.18342097,\n",
      "        -0.15122604,  0.52094781],\n",
      "       [ 0.09272826,  0.03007615,  0.20022175,  0.05541393, -0.27524808,\n",
      "         0.18227547, -0.30374685,  0.19198911, -0.07979605,  0.30987301,\n",
      "         0.35167289, -0.05390278, -0.38166636,  0.24773267, -0.18262525,\n",
      "        -0.21327467, -0.27502015, -0.03107289,  0.19233343, -0.00980713,\n",
      "         0.03788149, -0.11078653,  0.08148418,  0.39860171,  0.24514192,\n",
      "        -0.03593618,  0.07208899, -0.49928874, -0.22321789,  0.28490314,\n",
      "         0.07341097,  0.01843056],\n",
      "       [ 0.19120426, -0.33088461, -0.26179525, -0.17748265, -0.03040918,\n",
      "         0.15136941,  0.11514377,  0.26765215, -0.21635705,  0.00564941,\n",
      "         0.58783841, -0.19138311,  0.08707938,  0.01634824, -0.09745675,\n",
      "        -0.37015909, -0.29304504, -0.00221988,  0.21126547,  0.02173285,\n",
      "        -0.1392128 , -0.22327487,  0.41920632,  0.10215926,  0.08479935,\n",
      "        -0.2069454 , -0.14465894, -0.29240882, -0.30445838,  0.12436432,\n",
      "         0.10868951,  0.51126575],\n",
      "       [ 0.07089685, -0.1537029 , -0.21117596, -0.10633473, -0.16786602,\n",
      "         0.3455773 , -0.40873915, -0.03210416,  0.08406946,  0.12021432,\n",
      "         0.21254961, -0.26984739,  0.03112887, -0.27448869,  0.0358312 ,\n",
      "        -0.31082585, -0.23320381,  0.15563263, -0.21740878, -0.38301167,\n",
      "        -0.27006158,  0.22537443,  0.20186779,  0.25422731, -0.07861716,\n",
      "         0.05783036, -0.33317003, -0.00933458,  0.06723687, -0.25715554,\n",
      "         0.46594155,  0.47467586],\n",
      "       [ 0.19415268, -0.17481863, -0.32645851,  0.28460959,  0.20045885,\n",
      "         0.14756313, -0.29115134, -0.02816951, -0.13286979,  0.03709969,\n",
      "         0.28758916, -0.3483592 , -0.08758232,  0.34467062,  0.34724054,\n",
      "         0.11249474,  0.14247987,  0.08063367, -0.34348255, -0.10025993,\n",
      "        -0.14895479,  0.08400178,  0.08373213,  0.22745648, -0.05882907,\n",
      "        -0.20649688, -0.18068548,  0.21816632, -0.21568936,  0.30987242,\n",
      "         0.01662576,  0.17309543]], dtype=float32), array([-0.01539341,  0.        , -0.02564482,  0.        ,  0.24238965,\n",
      "       -0.08694378,  0.26591343, -0.02574808,  0.        , -0.01974789,\n",
      "       -0.1031177 , -0.00108856, -0.02097744,  0.        , -0.00805656,\n",
      "        0.26719615, -0.0431743 ,  0.10698286,  0.        ,  0.27770951,\n",
      "        0.        ,  0.        , -0.07393359, -0.05539808, -0.12656042,\n",
      "        0.        , -0.05476876,  0.23137933,  0.        , -0.03145207,\n",
      "       -0.09765293, -0.05591946], dtype=float32)]\n",
      "======================================================================================================\n",
      "\n",
      "Layer 3 weight: \n",
      "\n",
      " [array([[-0.17682901, -0.39444929],\n",
      "       [-0.0265463 , -0.27769679],\n",
      "       [-0.04709441,  0.31934974],\n",
      "       [-0.02594227, -0.04585364],\n",
      "       [ 0.62043905, -0.28630006],\n",
      "       [-0.43203509,  0.06749596],\n",
      "       [ 0.70524746, -0.16082485],\n",
      "       [ 0.1649918 , -0.28439221],\n",
      "       [-0.28849196, -0.08853787],\n",
      "       [ 0.00936558,  0.16675809],\n",
      "       [-0.41590819, -0.01187713],\n",
      "       [ 0.00216899,  0.32853475],\n",
      "       [-0.1183626 , -0.22453763],\n",
      "       [ 0.14270106, -0.10114336],\n",
      "       [ 0.21529794,  0.09155563],\n",
      "       [ 0.76459867, -0.07122314],\n",
      "       [-0.00383025,  0.26571235],\n",
      "       [ 0.23784927,  0.05496116],\n",
      "       [-0.41318029,  0.15962777],\n",
      "       [ 0.21426307, -0.62823147],\n",
      "       [-0.36329708, -0.01064456],\n",
      "       [ 0.38597867,  0.05006099],\n",
      "       [-0.32209834,  0.2666418 ],\n",
      "       [-0.58090013,  0.00264427],\n",
      "       [-0.49478245,  0.23480254],\n",
      "       [ 0.10163221,  0.21856967],\n",
      "       [-0.2820701 ,  0.18203981],\n",
      "       [ 0.25528154, -0.82034492],\n",
      "       [-0.31903422, -0.019923  ],\n",
      "       [-0.27391025, -0.13137154],\n",
      "       [-0.28530607,  0.51917052],\n",
      "       [-0.27751902,  0.57582003]], dtype=float32), array([ 0.12075055, -0.12075055], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print('======================================================================================================')\n",
    "    print(f'\\nLayer {i + 1} weight: \\n\\n', layer.get_weights()) # list of numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use `model.get_weight()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.11916009, -0.30759248, -0.04751443, -0.48624253, -0.42579335,\n",
       "          0.31345192,  0.34904912,  0.23672101,  0.75624794, -0.12187678,\n",
       "          0.4269982 ,  0.29224756,  0.1892598 ,  0.68758857,  0.72258794,\n",
       "         -0.26506439]], dtype=float32),\n",
       " array([ 0.        ,  0.        ,  0.24352528,  0.        ,  0.        ,\n",
       "         0.11395515,  0.18912597, -0.06024418, -0.1510088 ,  0.        ,\n",
       "        -0.1254327 , -0.06175768, -0.06024124, -0.13476065, -0.14081366,  0.        ], dtype=float32),\n",
       " array([[ 0.3069357 , -0.31109902,  0.05524549, -0.05416191, -0.1555647 ,\n",
       "          0.289103  ,  0.24298915, -0.29186827,  0.13510418,  0.1015529 ,\n",
       "         -0.02454144,  0.19875541,  0.14534298, -0.01244098, -0.10384941,\n",
       "          0.26365915, -0.06930619,  0.01960906,  0.24268928,  0.03361362,\n",
       "         -0.20039587, -0.22970293, -0.15259595,  0.31663182, -0.14352974,\n",
       "          0.27723423, -0.02870452, -0.24521963, -0.22228931,  0.23598525,\n",
       "         -0.15924749, -0.16258164],\n",
       "        [ 0.08632585, -0.30093515,  0.19478568,  0.34029594,  0.2275041 ,\n",
       "          0.22241178, -0.0343577 ,  0.08427414,  0.04572409,  0.05916423,\n",
       "          0.27613571, -0.06830874, -0.35176897,  0.06049564, -0.32074779,\n",
       "         -0.18216147,  0.24332878, -0.30870998,  0.22710368,  0.13576099,\n",
       "          0.32227901, -0.28103459,  0.27397129, -0.13553314, -0.24053273,\n",
       "          0.28664771,  0.16515991,  0.18535587,  0.05550411, -0.07019407,\n",
       "         -0.20539574,  0.20283195],\n",
       "        [-0.36924258, -0.30365658, -0.08808804, -0.34326854,  0.40230805,\n",
       "         -0.15413591,  0.05416599, -0.05220227,  0.06076613, -0.33502337,\n",
       "         -0.23688132,  0.09778441, -0.13928816, -0.30628562, -0.3254956 ,\n",
       "          0.43890026, -0.02866068,  0.35067967, -0.16505145,  0.00231954,\n",
       "         -0.30512244, -0.20576167,  0.21963552, -0.10038799, -0.07094997,\n",
       "         -0.1111248 ,  0.20207709,  0.52253139, -0.04829076,  0.20049232,\n",
       "         -0.22261173, -0.17694092],\n",
       "        [-0.26780131,  0.15646335, -0.08285001,  0.10862464, -0.33990657,\n",
       "         -0.18508384,  0.32404324, -0.01472056,  0.30441192,  0.26286045,\n",
       "         -0.02943662, -0.1773992 , -0.08054802, -0.03031757, -0.20453157,\n",
       "         -0.0173215 , -0.0439772 , -0.03734735,  0.06484294, -0.10689773,\n",
       "          0.07012519, -0.00758627, -0.23912561,  0.2489697 , -0.33535042,\n",
       "          0.23785743,  0.33387652,  0.08109316,  0.21725932,  0.04258373,\n",
       "          0.25407079,  0.14623708],\n",
       "        [ 0.00535342, -0.24750619,  0.12400302,  0.23234287, -0.05179805,\n",
       "          0.27566674, -0.07514057,  0.31823137, -0.08534038,  0.08020544,\n",
       "          0.12110248,  0.03589925,  0.34708461, -0.30863285, -0.23474547,\n",
       "         -0.04042193,  0.15496662,  0.0279099 ,  0.10684916,  0.34991172,\n",
       "          0.165176  ,  0.27750698, -0.31157672,  0.23462865,  0.29241475,\n",
       "          0.15076002, -0.00435957,  0.27937779, -0.33436579,  0.16600171,\n",
       "         -0.29466647,  0.31912836],\n",
       "        [-0.13160168, -0.23370495, -0.09790808, -0.18727766, -0.05146392,\n",
       "          0.25641996,  0.14972709, -0.06329995, -0.162635  , -0.07537787,\n",
       "          0.22205451, -0.08330593,  0.18038787, -0.18755558, -0.19531408,\n",
       "          0.2008501 ,  0.06353403,  0.06461938, -0.34208861,  0.42440885,\n",
       "          0.27876475, -0.10479738, -0.09521961,  0.21352957,  0.34211275,\n",
       "         -0.34111661,  0.1070687 ,  0.02749379,  0.04420412,  0.02738637,\n",
       "          0.31642792, -0.00267602],\n",
       "        [ 0.32192972, -0.27060956,  0.24569337, -0.22758809,  0.33776975,\n",
       "          0.10350902,  0.10619102, -0.29542324, -0.21133003,  0.28061688,\n",
       "          0.33129418, -0.23427604, -0.01935884,  0.00662616,  0.23077643,\n",
       "          0.22490561,  0.15082563, -0.14646178, -0.16953014,  0.13489789,\n",
       "         -0.14456823, -0.00316867, -0.06509987, -0.14504316,  0.39798024,\n",
       "          0.12055415, -0.04373154,  0.17976421, -0.04551184, -0.1123528 ,\n",
       "          0.38332674,  0.03633727],\n",
       "        [-0.03679751,  0.08841625, -0.03604515, -0.14171278, -0.19518118,\n",
       "          0.45724726, -0.10941526,  0.20900418,  0.20193139, -0.25457034,\n",
       "          0.55632299,  0.19019631, -0.01943509,  0.27025905,  0.01793735,\n",
       "          0.03409919, -0.00902436,  0.04133455,  0.33416912, -0.36688018,\n",
       "         -0.17686571,  0.09180671,  0.54240841,  0.20153655,  0.15983216,\n",
       "         -0.2235586 , -0.36391708,  0.1913828 , -0.22369532,  0.04585705,\n",
       "         -0.00476603,  0.18726967],\n",
       "        [-0.34722167,  0.31560293, -0.03883233,  0.22030547, -0.26013932,\n",
       "          0.4345606 , -0.14380766,  0.15668453,  0.05878222,  0.19397919,\n",
       "          0.35191417, -0.24075806,  0.0014064 , -0.24039972,  0.18167803,\n",
       "         -0.11913206,  0.26946557,  0.02627526, -0.23976314, -0.15507333,\n",
       "         -0.17379135, -0.24323866,  0.2255687 ,  0.41110215,  0.52564669,\n",
       "          0.19653144,  0.09724794, -0.2724874 , -0.15019366, -0.18542592,\n",
       "          0.25020334,  0.12325708],\n",
       "        [ 0.02456722,  0.21599409, -0.23195399,  0.32190159,  0.03943881,\n",
       "          0.24427608, -0.34408635,  0.26794109,  0.21411064, -0.20584504,\n",
       "          0.03960311, -0.30614796, -0.11312366, -0.11828943, -0.01322493,\n",
       "          0.23759833, -0.0576773 ,  0.04688543, -0.06288007, -0.1826335 ,\n",
       "          0.05099905, -0.31138134, -0.3184233 ,  0.12659624,  0.34493193,\n",
       "          0.14475882, -0.06736979,  0.31427351,  0.20016274,  0.16370282,\n",
       "         -0.28877047,  0.24249014],\n",
       "        [ 0.31072903, -0.06173703,  0.0333631 , -0.2481544 , -0.47613421,\n",
       "          0.17150049, -0.45164746, -0.11809359,  0.07879961,  0.27630419,\n",
       "          0.41751939, -0.29567102,  0.10333388, -0.0898329 ,  0.03492281,\n",
       "         -0.39618304, -0.32418159, -0.42702356,  0.03505799, -0.52159297,\n",
       "         -0.25507557, -0.00474378,  0.11839829,  0.30655816,  0.2284009 ,\n",
       "          0.0414162 , -0.34650153, -0.29481688, -0.21435575, -0.30369848,\n",
       "          0.0628026 , -0.08813549],\n",
       "        [-0.2834723 ,  0.32956317,  0.15808199, -0.10226268, -0.21273507,\n",
       "          0.25017777,  0.00296953, -0.32133701, -0.14811894,  0.09919962,\n",
       "          0.01800367, -0.05451611, -0.34759697,  0.05378106, -0.32738528,\n",
       "          0.00542432,  0.27419007,  0.20093316,  0.13437435, -0.20991971,\n",
       "         -0.11866917, -0.15441079,  0.13374051,  0.5045405 ,  0.10101692,\n",
       "          0.07254559, -0.06487841, -0.19663534, -0.27566659, -0.18342097,\n",
       "         -0.15122604,  0.52094781],\n",
       "        [ 0.09272826,  0.03007615,  0.20022175,  0.05541393, -0.27524808,\n",
       "          0.18227547, -0.30374685,  0.19198911, -0.07979605,  0.30987301,\n",
       "          0.35167289, -0.05390278, -0.38166636,  0.24773267, -0.18262525,\n",
       "         -0.21327467, -0.27502015, -0.03107289,  0.19233343, -0.00980713,\n",
       "          0.03788149, -0.11078653,  0.08148418,  0.39860171,  0.24514192,\n",
       "         -0.03593618,  0.07208899, -0.49928874, -0.22321789,  0.28490314,\n",
       "          0.07341097,  0.01843056],\n",
       "        [ 0.19120426, -0.33088461, -0.26179525, -0.17748265, -0.03040918,\n",
       "          0.15136941,  0.11514377,  0.26765215, -0.21635705,  0.00564941,\n",
       "          0.58783841, -0.19138311,  0.08707938,  0.01634824, -0.09745675,\n",
       "         -0.37015909, -0.29304504, -0.00221988,  0.21126547,  0.02173285,\n",
       "         -0.1392128 , -0.22327487,  0.41920632,  0.10215926,  0.08479935,\n",
       "         -0.2069454 , -0.14465894, -0.29240882, -0.30445838,  0.12436432,\n",
       "          0.10868951,  0.51126575],\n",
       "        [ 0.07089685, -0.1537029 , -0.21117596, -0.10633473, -0.16786602,\n",
       "          0.3455773 , -0.40873915, -0.03210416,  0.08406946,  0.12021432,\n",
       "          0.21254961, -0.26984739,  0.03112887, -0.27448869,  0.0358312 ,\n",
       "         -0.31082585, -0.23320381,  0.15563263, -0.21740878, -0.38301167,\n",
       "         -0.27006158,  0.22537443,  0.20186779,  0.25422731, -0.07861716,\n",
       "          0.05783036, -0.33317003, -0.00933458,  0.06723687, -0.25715554,\n",
       "          0.46594155,  0.47467586],\n",
       "        [ 0.19415268, -0.17481863, -0.32645851,  0.28460959,  0.20045885,\n",
       "          0.14756313, -0.29115134, -0.02816951, -0.13286979,  0.03709969,\n",
       "          0.28758916, -0.3483592 , -0.08758232,  0.34467062,  0.34724054,\n",
       "          0.11249474,  0.14247987,  0.08063367, -0.34348255, -0.10025993,\n",
       "         -0.14895479,  0.08400178,  0.08373213,  0.22745648, -0.05882907,\n",
       "         -0.20649688, -0.18068548,  0.21816632, -0.21568936,  0.30987242,\n",
       "          0.01662576,  0.17309543]], dtype=float32),\n",
       " array([-0.01539341,  0.        , -0.02564482,  0.        ,  0.24238965,\n",
       "        -0.08694378,  0.26591343, -0.02574808,  0.        , -0.01974789,\n",
       "        -0.1031177 , -0.00108856, -0.02097744,  0.        , -0.00805656,\n",
       "         0.26719615, -0.0431743 ,  0.10698286,  0.        ,  0.27770951,\n",
       "         0.        ,  0.        , -0.07393359, -0.05539808, -0.12656042,\n",
       "         0.        , -0.05476876,  0.23137933,  0.        , -0.03145207,\n",
       "        -0.09765293, -0.05591946], dtype=float32),\n",
       " array([[-0.17682901, -0.39444929],\n",
       "        [-0.0265463 , -0.27769679],\n",
       "        [-0.04709441,  0.31934974],\n",
       "        [-0.02594227, -0.04585364],\n",
       "        [ 0.62043905, -0.28630006],\n",
       "        [-0.43203509,  0.06749596],\n",
       "        [ 0.70524746, -0.16082485],\n",
       "        [ 0.1649918 , -0.28439221],\n",
       "        [-0.28849196, -0.08853787],\n",
       "        [ 0.00936558,  0.16675809],\n",
       "        [-0.41590819, -0.01187713],\n",
       "        [ 0.00216899,  0.32853475],\n",
       "        [-0.1183626 , -0.22453763],\n",
       "        [ 0.14270106, -0.10114336],\n",
       "        [ 0.21529794,  0.09155563],\n",
       "        [ 0.76459867, -0.07122314],\n",
       "        [-0.00383025,  0.26571235],\n",
       "        [ 0.23784927,  0.05496116],\n",
       "        [-0.41318029,  0.15962777],\n",
       "        [ 0.21426307, -0.62823147],\n",
       "        [-0.36329708, -0.01064456],\n",
       "        [ 0.38597867,  0.05006099],\n",
       "        [-0.32209834,  0.2666418 ],\n",
       "        [-0.58090013,  0.00264427],\n",
       "        [-0.49478245,  0.23480254],\n",
       "        [ 0.10163221,  0.21856967],\n",
       "        [-0.2820701 ,  0.18203981],\n",
       "        [ 0.25528154, -0.82034492],\n",
       "        [-0.31903422, -0.019923  ],\n",
       "        [-0.27391025, -0.13137154],\n",
       "        [-0.28530607,  0.51917052],\n",
       "        [-0.27751902,  0.57582003]], dtype=float32),\n",
       " array([ 0.12075055, -0.12075055], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 1),\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'dtype': 'float32',\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_4',\n",
       "   'trainable': True,\n",
       "   'units': 16,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_5',\n",
       "   'trainable': True,\n",
       "   'units': 32,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'softmax',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_6',\n",
       "   'trainable': True,\n",
       "   'units': 2,\n",
       "   'use_bias': True}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x7f6d3eedc470>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/loading only a model's architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to save the architecture of a model, and not its weights or its training configuration, we can use the `to_json()` or `to_yaml()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "# save as YAML\n",
    "yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated JSON / YAML files are human-readable and can be manually edited if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_6\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.1.2\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backend: tensorflow\\nclass_name: Sequential\\nconfig:\\n- class_name: Dense\\n  config:\\n    activation: relu\\n    activity_regularizer: null\\n    batch_input_shape: !!python/tuple [null, 1]\\n    bias_constraint: null\\n    bias_initializer:\\n      class_name: Zeros\\n      config: {}\\n    bias_regularizer: null\\n    dtype: float32\\n    kernel_constraint: null\\n    kernel_initializer:\\n      class_name: VarianceScaling\\n      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\\n    kernel_regularizer: null\\n    name: dense_4\\n    trainable: true\\n    units: 16\\n    use_bias: true\\n- class_name: Dense\\n  config:\\n    activation: relu\\n    activity_regularizer: null\\n    bias_constraint: null\\n    bias_initializer:\\n      class_name: Zeros\\n      config: {}\\n    bias_regularizer: null\\n    kernel_constraint: null\\n    kernel_initializer:\\n      class_name: VarianceScaling\\n      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\\n    kernel_regularizer: null\\n    name: dense_5\\n    trainable: true\\n    units: 32\\n    use_bias: true\\n- class_name: Dense\\n  config:\\n    activation: softmax\\n    activity_regularizer: null\\n    bias_constraint: null\\n    bias_initializer:\\n      class_name: Zeros\\n      config: {}\\n    bias_regularizer: null\\n    kernel_constraint: null\\n    kernel_initializer:\\n      class_name: VarianceScaling\\n      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\\n    kernel_regularizer: null\\n    name: dense_6\\n    trainable: true\\n    units: 2\\n    use_bias: true\\nkeras_version: 2.1.2\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "- class_name: Dense\n",
      "  config:\n",
      "    activation: relu\n",
      "    activity_regularizer: null\n",
      "    batch_input_shape: !!python/tuple [null, 1]\n",
      "    bias_constraint: null\n",
      "    bias_initializer:\n",
      "      class_name: Zeros\n",
      "      config: {}\n",
      "    bias_regularizer: null\n",
      "    dtype: float32\n",
      "    kernel_constraint: null\n",
      "    kernel_initializer:\n",
      "      class_name: VarianceScaling\n",
      "      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\n",
      "    kernel_regularizer: null\n",
      "    name: dense_4\n",
      "    trainable: true\n",
      "    units: 16\n",
      "    use_bias: true\n",
      "- class_name: Dense\n",
      "  config:\n",
      "    activation: relu\n",
      "    activity_regularizer: null\n",
      "    bias_constraint: null\n",
      "    bias_initializer:\n",
      "      class_name: Zeros\n",
      "      config: {}\n",
      "    bias_regularizer: null\n",
      "    kernel_constraint: null\n",
      "    kernel_initializer:\n",
      "      class_name: VarianceScaling\n",
      "      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\n",
      "    kernel_regularizer: null\n",
      "    name: dense_5\n",
      "    trainable: true\n",
      "    units: 32\n",
      "    use_bias: true\n",
      "- class_name: Dense\n",
      "  config:\n",
      "    activation: softmax\n",
      "    activity_regularizer: null\n",
      "    bias_constraint: null\n",
      "    bias_initializer:\n",
      "      class_name: Zeros\n",
      "      config: {}\n",
      "    bias_regularizer: null\n",
      "    kernel_constraint: null\n",
      "    kernel_initializer:\n",
      "      class_name: VarianceScaling\n",
      "      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\n",
      "    kernel_regularizer: null\n",
      "    name: dense_6\n",
      "    trainable: true\n",
      "    units: 2\n",
      "    use_bias: true\n",
      "keras_version: 2.1.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need to print yaml_string to view it properly\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from JSON:\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model reconstruction from YAML\n",
    "from keras.models import model_from_yaml\n",
    "model = model_from_yaml(yaml_string)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's look at the weight of layer 1. It should be something random because we only loaded the architecture. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18652165,  0.43917835,  0.10884571, -0.29585958, -0.2830998 ,\n",
       "         0.42854798, -0.1439566 ,  0.31404907, -0.08831829, -0.37302232,\n",
       "        -0.20548066,  0.26590091, -0.44459176,  0.15210241,  0.14192462,\n",
       "         0.4903729 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/loading only a model's weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to save the weights of a model, you can use the following function save the weights only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the model we saved\n",
    "model = load_model('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only weight\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting model\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating same model (only architecture)\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer = Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11916009, -0.30759248, -0.04751443, -0.48624253, -0.42579335,\n",
       "         0.31345192,  0.34904912,  0.23672101,  0.75624794, -0.12187678,\n",
       "         0.4269982 ,  0.29224756,  0.1892598 ,  0.68758857,  0.72258794,\n",
       "        -0.26506439]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get weight of 1st layer\n",
    "model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are same as the model we have created.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So those are three way to save either Model architecture, weight or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels =  []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data have 420 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making something Similar like training Data\n",
    "\n",
    "for i in range(10):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data = {\"Age\": test_samples, \"Side Effect?\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Side Effect?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Side Effect?\n",
       "0   55             1\n",
       "1   87             0\n",
       "2   13             1\n",
       "3   86             0\n",
       "4   38             1\n",
       "5   85             0\n",
       "6   36             1\n",
       "7   92             0\n",
       "8   39             1\n",
       "9   76             0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_test['Age'] = df_test['Age'].astype(float)\n",
    "df_test['Age'] = scaler.fit_transform((df_test['Age']).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Side Effect?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.850575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.839080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.827586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.264368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.908046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.298851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.724138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Side Effect?\n",
       "0  0.482759             1\n",
       "1  0.850575             0\n",
       "2  0.000000             1\n",
       "3  0.839080             0\n",
       "4  0.287356             1\n",
       "5  0.827586             0\n",
       "6  0.264368             1\n",
       "7  0.908046             0\n",
       "8  0.298851             1\n",
       "9  0.724138             0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates output predictions for the input samples.\n",
    "\n",
    "Computation is done in batches.\n",
    "\n",
    "The input data is a Numpy array (or list of Numpy arrays if the model has multiple inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(df_test['Age'], batch_size=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.60793728,  0.39206266],\n",
       "       [ 0.10429747,  0.89570254],\n",
       "       [ 0.88056672,  0.11943327],\n",
       "       [ 0.11210135,  0.88789862],\n",
       "       [ 0.85619229,  0.14380769],\n",
       "       [ 0.12041058,  0.87958938],\n",
       "       [ 0.8664462 ,  0.13355379],\n",
       "       [ 0.07266858,  0.92733145],\n",
       "       [ 0.84845155,  0.1515485 ],\n",
       "       [ 0.220907  ,  0.77909297],\n",
       "       [ 0.88526392,  0.11473608],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.11210135,  0.88789862],\n",
       "       [ 0.88319647,  0.11680356],\n",
       "       [ 0.12041058,  0.87958938],\n",
       "       [ 0.74760938,  0.25239059],\n",
       "       [ 0.05860985,  0.94139016],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.09011973,  0.90988022],\n",
       "       [ 0.82797486,  0.17202514],\n",
       "       [ 0.04848356,  0.95151645],\n",
       "       [ 0.77690423,  0.22309577],\n",
       "       [ 0.09011973,  0.90988022],\n",
       "       [ 0.58849406,  0.41150594],\n",
       "       [ 0.08370187,  0.91629815],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.19431664,  0.80568337],\n",
       "       [ 0.88267457,  0.11732545],\n",
       "       [ 0.33313441,  0.66686559],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.64576226,  0.35423774],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.54882652,  0.45117348],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.87501431,  0.12498576],\n",
       "       [ 0.07266858,  0.92733145],\n",
       "       [ 0.62704408,  0.37295598],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.88577574,  0.11422421],\n",
       "       [ 0.33313441,  0.66686559],\n",
       "       [ 0.88577574,  0.11422421],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.10429749,  0.89570254],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.88673639,  0.11326355],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.88673639,  0.11326355],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.69913512,  0.30086488],\n",
       "       [ 0.22090702,  0.77909297],\n",
       "       [ 0.88750511,  0.11249483],\n",
       "       [ 0.05590627,  0.94409376],\n",
       "       [ 0.88526392,  0.11473608],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.64576226,  0.35423774],\n",
       "       [ 0.29820597,  0.70179397],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.19431664,  0.80568337],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.66404438,  0.33595571],\n",
       "       [ 0.18196243,  0.81803757],\n",
       "       [ 0.7906127 ,  0.20938733],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.87880975,  0.12119027],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.87501431,  0.12498576],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.88752258,  0.1124774 ],\n",
       "       [ 0.0901197 ,  0.90988034],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.28155488,  0.71844518],\n",
       "       [ 0.71587461,  0.28412539],\n",
       "       [ 0.10429747,  0.89570254],\n",
       "       [ 0.83876181,  0.16123816],\n",
       "       [ 0.17022763,  0.82977241],\n",
       "       [ 0.48830479,  0.51169527],\n",
       "       [ 0.07794072,  0.9220593 ],\n",
       "       [ 0.66404438,  0.33595571],\n",
       "       [ 0.31540954,  0.68459046],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.1292461 ,  0.87075388],\n",
       "       [ 0.88109672,  0.11890325],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.88109672,  0.11890325],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.33313441,  0.66686559],\n",
       "       [ 0.88109672,  0.11890325],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.88056672,  0.11943327],\n",
       "       [ 0.05332031,  0.94667965],\n",
       "       [ 0.64576226,  0.35423774],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.7906127 ,  0.20938733],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.54882652,  0.45117348],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.73203981,  0.26796025],\n",
       "       [ 0.11210135,  0.88789862],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.19431664,  0.80568337],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.88673639,  0.11326355],\n",
       "       [ 0.1292461 ,  0.87075388],\n",
       "       [ 0.8816247 ,  0.11837529],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.48830479,  0.51169527],\n",
       "       [ 0.19431661,  0.80568337],\n",
       "       [ 0.88577574,  0.11422421],\n",
       "       [ 0.17022763,  0.82977241],\n",
       "       [ 0.8870331 ,  0.11296693],\n",
       "       [ 0.23514536,  0.76485467],\n",
       "       [ 0.8664462 ,  0.13355379],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.88319647,  0.11680356],\n",
       "       [ 0.17022763,  0.82977241],\n",
       "       [ 0.64576226,  0.35423779],\n",
       "       [ 0.05590627,  0.94409376],\n",
       "       [ 0.88752258,  0.1124774 ],\n",
       "       [ 0.23514536,  0.76485467],\n",
       "       [ 0.87109649,  0.12890348],\n",
       "       [ 0.1591025 ,  0.84089756],\n",
       "       [ 0.86140788,  0.13859212],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.87109649,  0.12890348],\n",
       "       [ 0.17022763,  0.82977241],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.28155485,  0.71844506],\n",
       "       [ 0.76256782,  0.23743221],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.71587461,  0.28412539],\n",
       "       [ 0.06143982,  0.93856019],\n",
       "       [ 0.8664462 ,  0.13355379],\n",
       "       [ 0.29820597,  0.70179397],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.06476914,  0.93523079],\n",
       "       [ 0.84845155,  0.1515485 ],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.4681192 ,  0.53188074],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.80369163,  0.19630836],\n",
       "       [ 0.1292461 ,  0.87075388],\n",
       "       [ 0.86140788,  0.13859212],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.8816247 ,  0.11837529],\n",
       "       [ 0.26548174,  0.73451823],\n",
       "       [ 0.88056672,  0.11943327],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.13862778,  0.86137223],\n",
       "       [ 0.85619229,  0.14380769],\n",
       "       [ 0.23514536,  0.76485467],\n",
       "       [ 0.8664462 ,  0.13355379],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.88267457,  0.11732545],\n",
       "       [ 0.06143982,  0.93856019],\n",
       "       [ 0.68184775,  0.31815228],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.88267457,  0.11732545],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.68184769,  0.31815228],\n",
       "       [ 0.17022763,  0.82977241],\n",
       "       [ 0.4681192 ,  0.53188074],\n",
       "       [ 0.05332031,  0.94667965],\n",
       "       [ 0.8864392 ,  0.11356087],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.87880975,  0.12119027],\n",
       "       [ 0.29820597,  0.70179397],\n",
       "       [ 0.4681192 ,  0.53188074],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.74760938,  0.25239059],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.86140788,  0.13859212],\n",
       "       [ 0.29820597,  0.70179397],\n",
       "       [ 0.68184775,  0.31815228],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.54882652,  0.45117348],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.7906127 ,  0.20938733],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.88215065,  0.11784936],\n",
       "       [ 0.13862778,  0.86137223],\n",
       "       [ 0.88056672,  0.11943327],\n",
       "       [ 0.22090702,  0.77909297],\n",
       "       [ 0.50852853,  0.49147153],\n",
       "       [ 0.06836286,  0.93163717],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.73203981,  0.26796025],\n",
       "       [ 0.26548174,  0.73451823],\n",
       "       [ 0.77690423,  0.22309577],\n",
       "       [ 0.05860985,  0.94139016],\n",
       "       [ 0.82797486,  0.17202514],\n",
       "       [ 0.06476914,  0.93523079],\n",
       "       [ 0.66404438,  0.33595571],\n",
       "       [ 0.05332031,  0.94667965],\n",
       "       [ 0.7906127 ,  0.20938733],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.83876181,  0.16123816],\n",
       "       [ 0.29820597,  0.70179397],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.12041058,  0.87958938],\n",
       "       [ 0.84845155,  0.1515485 ],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.88750511,  0.11249483],\n",
       "       [ 0.33313441,  0.66686559],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.1591025 ,  0.84089756],\n",
       "       [ 0.8816247 ,  0.11837529],\n",
       "       [ 0.18196243,  0.81803757],\n",
       "       [ 0.88750511,  0.11249486],\n",
       "       [ 0.29820597,  0.70179397],\n",
       "       [ 0.58849406,  0.41150594],\n",
       "       [ 0.22090702,  0.77909297],\n",
       "       [ 0.8816247 ,  0.11837529],\n",
       "       [ 0.13862774,  0.86137223],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.77690423,  0.22309577],\n",
       "       [ 0.13862778,  0.86137223],\n",
       "       [ 0.88577574,  0.11422421],\n",
       "       [ 0.09011973,  0.90988022],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.07266858,  0.92733145],\n",
       "       [ 0.88614112,  0.11385883],\n",
       "       [ 0.23514539,  0.76485461],\n",
       "       [ 0.68184769,  0.31815228],\n",
       "       [ 0.19431664,  0.80568337],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.19431664,  0.80568337],\n",
       "       [ 0.71587461,  0.28412539],\n",
       "       [ 0.06476914,  0.93523079],\n",
       "       [ 0.7906127 ,  0.20938733],\n",
       "       [ 0.26548174,  0.73451823],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.04848356,  0.95151645],\n",
       "       [ 0.88614112,  0.11385883],\n",
       "       [ 0.05332031,  0.94667965],\n",
       "       [ 0.88267457,  0.11732545],\n",
       "       [ 0.1292461 ,  0.87075388],\n",
       "       [ 0.84845155,  0.1515485 ],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.88202989,  0.11797009],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.83876181,  0.16123816],\n",
       "       [ 0.14857422,  0.85142583],\n",
       "       [ 0.50852853,  0.49147153],\n",
       "       [ 0.18196243,  0.81803757],\n",
       "       [ 0.52872425,  0.47127575],\n",
       "       [ 0.14857422,  0.85142583],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.05860985,  0.94139016],\n",
       "       [ 0.88109672,  0.11890325],\n",
       "       [ 0.05590627,  0.94409376],\n",
       "       [ 0.68184769,  0.31815228],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.4681192 ,  0.53188074],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.88511139,  0.11488861],\n",
       "       [ 0.22090702,  0.77909297],\n",
       "       [ 0.8864392 ,  0.11356087],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.71587461,  0.28412539],\n",
       "       [ 0.28155485,  0.71844506],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.88732904,  0.11267097],\n",
       "       [ 0.17022763,  0.82977241],\n",
       "       [ 0.85619229,  0.14380769],\n",
       "       [ 0.08370187,  0.91629815],\n",
       "       [ 0.4681192 ,  0.53188074],\n",
       "       [ 0.14857422,  0.85142583],\n",
       "       [ 0.88475007,  0.11524996],\n",
       "       [ 0.0901197 ,  0.90988034],\n",
       "       [ 0.88215065,  0.11784936],\n",
       "       [ 0.05860985,  0.94139016],\n",
       "       [ 0.88109672,  0.11890325],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.88511139,  0.11488861],\n",
       "       [ 0.1591025 ,  0.84089756],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.76256782,  0.23743221],\n",
       "       [ 0.28155488,  0.71844518],\n",
       "       [ 0.77690423,  0.22309577],\n",
       "       [ 0.28155488,  0.71844518],\n",
       "       [ 0.88319647,  0.11680356],\n",
       "       [ 0.14857422,  0.85142583],\n",
       "       [ 0.77690423,  0.22309577],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.88202989,  0.11797009],\n",
       "       [ 0.04848355,  0.95151645],\n",
       "       [ 0.88614112,  0.11385883],\n",
       "       [ 0.12041058,  0.87958938],\n",
       "       [ 0.69913512,  0.30086488],\n",
       "       [ 0.06143982,  0.93856019],\n",
       "       [ 0.52872425,  0.47127575],\n",
       "       [ 0.06836284,  0.93163717],\n",
       "       [ 0.68184769,  0.31815228],\n",
       "       [ 0.20729721,  0.79270285],\n",
       "       [ 0.88423419,  0.11576582],\n",
       "       [ 0.06476914,  0.93523079],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.1591025 ,  0.84089756],\n",
       "       [ 0.80369163,  0.19630836],\n",
       "       [ 0.28155488,  0.71844518],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.42812401,  0.57187605],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.23514539,  0.76485461],\n",
       "       [ 0.88673639,  0.11326355],\n",
       "       [ 0.05590628,  0.94409376],\n",
       "       [ 0.88511139,  0.11488861],\n",
       "       [ 0.31540954,  0.68459046],\n",
       "       [ 0.87109649,  0.12890348],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.88750511,  0.11249486],\n",
       "       [ 0.38904634,  0.61095369],\n",
       "       [ 0.73203981,  0.26796025],\n",
       "       [ 0.0901197 ,  0.90988034],\n",
       "       [ 0.81614363,  0.18385635],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.88673639,  0.11326355],\n",
       "       [ 0.10429747,  0.89570254],\n",
       "       [ 0.88750511,  0.11249486],\n",
       "       [ 0.12041058,  0.87958938],\n",
       "       [ 0.44803765,  0.55196238],\n",
       "       [ 0.25000697,  0.74999309],\n",
       "       [ 0.74760938,  0.25239065],\n",
       "       [ 0.1591025 ,  0.84089756],\n",
       "       [ 0.88752258,  0.1124774 ],\n",
       "       [ 0.11210135,  0.88789862],\n",
       "       [ 0.68184769,  0.31815228],\n",
       "       [ 0.09011973,  0.90988022],\n",
       "       [ 0.8816247 ,  0.11837529],\n",
       "       [ 0.09011973,  0.90988022],\n",
       "       [ 0.83876181,  0.16123816],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.86140788,  0.13859211],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.54882652,  0.45117348],\n",
       "       [ 0.18196243,  0.81803757],\n",
       "       [ 0.8664462 ,  0.13355379],\n",
       "       [ 0.3699972 ,  0.6300028 ],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.05084754,  0.94915253],\n",
       "       [ 0.48830479,  0.51169527],\n",
       "       [ 0.19431664,  0.80568337],\n",
       "       [ 0.88371629,  0.11628368],\n",
       "       [ 0.1591025 ,  0.84089756],\n",
       "       [ 0.88732904,  0.11267097],\n",
       "       [ 0.14857422,  0.85142583],\n",
       "       [ 0.54882652,  0.45117348],\n",
       "       [ 0.09011973,  0.90988022],\n",
       "       [ 0.56877053,  0.43122944],\n",
       "       [ 0.22090702,  0.77909297],\n",
       "       [ 0.52872425,  0.47127575],\n",
       "       [ 0.3513442 ,  0.64865577],\n",
       "       [ 0.88215065,  0.11784936],\n",
       "       [ 0.08370187,  0.91629815],\n",
       "       [ 0.71587461,  0.28412539],\n",
       "       [ 0.06143982,  0.93856019],\n",
       "       [ 0.56877053,  0.43122944],\n",
       "       [ 0.31540954,  0.68459046],\n",
       "       [ 0.52872425,  0.47127575],\n",
       "       [ 0.33313441,  0.66686559],\n",
       "       [ 0.71587461,  0.28412539],\n",
       "       [ 0.40844053,  0.59155941],\n",
       "       [ 0.66404438,  0.33595571],\n",
       "       [ 0.04848355,  0.95151645],\n",
       "       [ 0.4681192 ,  0.53188074],\n",
       "       [ 0.33313441,  0.66686559],\n",
       "       [ 0.50852853,  0.49147153],\n",
       "       [ 0.11210135,  0.88789862],\n",
       "       [ 0.54882652,  0.45117348],\n",
       "       [ 0.26548174,  0.73451823],\n",
       "       [ 0.82797486,  0.17202514],\n",
       "       [ 0.07794072,  0.9220593 ],\n",
       "       [ 0.48830479,  0.51169527],\n",
       "       [ 0.06476914,  0.93523079],\n",
       "       [ 0.88109672,  0.11890325],\n",
       "       [ 0.04848356,  0.95151645],\n",
       "       [ 0.88475007,  0.11524996],\n",
       "       [ 0.05332031,  0.94667965],\n",
       "       [ 0.8864392 ,  0.11356087],\n",
       "       [ 0.11210135,  0.88789862],\n",
       "       [ 0.64576226,  0.35423774],\n",
       "       [ 0.22090702,  0.77909297],\n",
       "       [ 0.7906127 ,  0.20938733],\n",
       "       [ 0.05860985,  0.94139016],\n",
       "       [ 0.56877053,  0.43122944],\n",
       "       [ 0.0969776 ,  0.90302247],\n",
       "       [ 0.84845155,  0.1515485 ],\n",
       "       [ 0.26548174,  0.73451823],\n",
       "       [ 0.88732904,  0.11267097],\n",
       "       [ 0.12041058,  0.87958938],\n",
       "       [ 0.60793728,  0.39206266],\n",
       "       [ 0.05332031,  0.94667965],\n",
       "       [ 0.66404438,  0.33595571],\n",
       "       [ 0.18196243,  0.81803757]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that prediction is a array of array. Remember we have 2 output node. One output node is for 0 and other is for 1. So basically Here we have probability of patient not having any adverse reaction and patient having an adverse reaction after taking the drug. If we add us the probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0] + predictions[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very close to one (or maybe 1). Because the total probability is always 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict in either 0 or 1 we can use `predict_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(df_test['Age'], batch_size=10, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at `Out[50]`, we will find that the probability of 0 is 60.793728% and 1 is 39.206266% for first sample. Hence the prediction is classified as 0.\n",
    "\n",
    "For 2nd sample the probability of 0 is 10.429747% and 1 is 89.570254% and hence it is classified as 1.\n",
    "\n",
    "Likewise other are classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matplotlib plot within Jupyter Notebook\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_test['Side Effect?'], rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[182  28]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d3c0f46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects','had_side_effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In gist confusion matrix tells us about:\n",
    "\n",
    "* **true positives (TP)**: These are cases in which we predicted yes (they have the side effect), and they do have the side effects. Here we predicted that 200 of them have side effect and they really do have side effect.\n",
    "\n",
    "* **true negatives (TN)**: We predicted no they don't have any side effect, and they don't have the side effect. Here we predicted 182 have no side effect and they really do not have any side effect.\n",
    "\n",
    "* **false positives (FP)**: We predicted yes, but they don't actually have the side effect. (Also known as a \"**Type I error**\"). Here we predicted 28 of them have side effect but they do not have any side effect.\n",
    "\n",
    "* **false negatives (FN)**: We predicted no, but they actually do have the side effect. (Also known as a \"**Type II error**\"). Here we predicted 10 of them have no side effect but they do have some kind of side effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on confussion matrix we can have these rate values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**: Overall, how often is the classifier correct?\n",
    "(TP+TN)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90952380952380951"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[0][0] + cm[1][1])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Misclassification Rate**: Overall, how often is it wrong?\n",
    "(FP+FN)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090476190476190474"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[0][1] + cm[1][0])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to 1 minus Accuracy and also known as \"Error Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090476190476190488"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (cm[0][0] + cm[1][1])/np.sum(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positive Rate**: When it's actually yes, how often does it predict yes? TN/actual yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95238095238095233"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1] / (cm[1][0] + cm[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also known as \"**Sensitivity**\" or \"**Recall**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate**: When it's actually no, how often does it predict yes? FP/actual no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0][0] / (cm[0][1] + cm[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity**: When it's actually no, how often does it predict no? TN/actual no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equivalent to 1 minus False Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**: When it predicts yes, how often is it correct? TP/predicted yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prevalence**: How often does the yes condition actually occur in our sample? actual yes/total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
